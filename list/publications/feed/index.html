<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Publications &#8211; Angelos Barmpoutis</title>
	<atom:link href="https://research.dwi.ufl.edu/projects/angelos/list/publications/feed/" rel="self" type="application/rss+xml" />
	<link>https://research.dwi.ufl.edu/projects/angelos</link>
	<description>Professor</description>
	<lastBuildDate>Sun, 06 Sep 2020 16:17:29 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.2</generator>
	<item>
		<title>Virtual Kayaking: A study on the effect of low-cost passive haptics on the user experience while exercising</title>
		<link>https://research.dwi.ufl.edu/projects/angelos/page/virtual-kayaking-a-study-on-the-effect-of-low-cost-passive-haptics-on-the-user-experience-while-exercising/</link>
		
		<dc:creator><![CDATA[angelos]]></dc:creator>
		<pubDate>Thu, 16 Jul 2020 14:44:20 +0000</pubDate>
				<guid isPermaLink="false">https://research.dwi.ufl.edu/people/angelos/?post_type=product&#038;p=35</guid>

					<description><![CDATA[This paper presents the results of a pilot study that assesses the effect of passive haptics on the user experience in virtual reality simulations of recreation and sports activities. A virtual reality kayaking environment with realistic physics simulation and water rendering was developed that allowed users to steer the kayak using natural motions. Within this<span class="read-more-faq"><a href="https://research.dwi.ufl.edu/projects/angelos/page/virtual-kayaking-a-study-on-the-effect-of-low-cost-passive-haptics-on-the-user-experience-while-exercising/">Read More</a></span>]]></description>
										<content:encoded><![CDATA[<p><iframe src="https://www.youtube.com/embed/QiO9ZzyffAY?feature=oembed" width="1200" height="600" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>This paper presents the results of a pilot study that assesses the effect of passive haptics on the user experience in virtual reality simulations of recreation and sports activities. A virtual reality kayaking environment with realistic physics simulation and water rendering was developed that allowed users to steer the kayak using natural motions. Within this environment the users experienced two different ways of paddling using: a) a pair of typical virtual reality controllers, and b) one custom-made “smart paddle” that provided the passive haptic feedback of a real paddle. The results of this pilot study indicate that the users learned faster how to steer the kayak using the paddle, which they found to be more intuitive to use and more appropriate for this application. The results also demonstrated an increase in the perceived level of enjoyment and realism of the virtual experience.</p>
<p>Kayaking is an outdoor activity that can be enjoyed with easy motions and with minimal skill, and can be performed on equal terms by both people who are physically able and those with disabilities [1]. For this reason, it is an ideal exercise for physical therapy and its efficacy as a rehabilitation tool has been demonstrated in several studies [1-6]. Kayaking simulations offer a minimal-risk environment, which, in addition to rehabilitation, can be used in training and recreational applications [5]. The mechanics of boat simulation in general have been well-studied and led to the design of high-fidelity simulation systems in the past decades [3,7]. These simulators immerse the users by rendering a virtual environment on a projector [1,4,6] or a computer screen that is mounted on the simulator system [2,8]. Furthermore, the users can control the simulation by imitating kayaking motions using remote controls equipped with accelerometers (such as Wii controllers) [5] or by performing the same motions in front of a kinesthetic sensor (such as Kinect sensors) [4,6].</p>
<p>The recent advances in virtual reality technologies and in particular the availability of head mounted displays as self-contained low-cost consumer devices led to the development of highly immersive virtual experiences compared to the conventional virtual reality experiences with wall projectors and computer displays. Kayaking simulations have been published as commercial game titles in these virtual reality platforms [13]. However, the use of head mounted displays in intensive physical therapy exercises bears the risk of serious injuries due to the lack of user contact with the real environment. These risks could potentially be reduced if the users maintained continuous contact with the surrounding objects such as the simulator hardware, the paddle(s), and the floor of the room, with the use of passive haptics. Additionally, the overall user experience can be improved through sensory-rich interaction with the key components of the simulated environment.</p>
<p>This paper assesses the role of passive haptics in virtual kayaking applications. Passive haptics can be implemented in virtual reality systems by tracking objects of interest in real-time and aligning them with identically shaped virtual objects, which results in a sensory-rich experience [9,10]. This alignment between real and virtual objects allows users to hold and feel the main objects of interaction including hand-held objects, tables, walls, and various tools [11,12].</p>
<p>In this paper we present a novel virtual reality kayaking application with passive haptic feedback on the key objects of interaction, namely the paddle and the kayak seat. These objects are being tracked in real-time with commercially available tracking sensors that are firmly attached to them. Although the users’ real-world view is occluded by the head-mounted display, the users can see the virtual representation of these objects and naturally feel, hold, and interact with them. Subsequently, the users can perform natural maneuvers during the virtual kayaking experience by interacting with our “smart” paddle using the same range of motions as in real kayaking.</p>
<p>The proposed system was assessed with a pilot user study (n=10) that tested the following hypotheses: a) The use of passive haptics helps users learn kayaking faster and operate the simulation better compared to the conventional controller-based interaction. b) The use of passive haptics improves the level of immersion while kayaking in virtual reality.</p>
<p>The study was undertaken at the Realities Lab of the Digital Worlds Institute at the University of Florida. The volunteers who participated in this experiment were randomly assigned to the study and the control group and experienced the proposed virtual kayaking system with and without the use of passive haptics respectively. The data collection was performed with pre- and post-test surveys. In addition, the progress of each individual user during kayaking was recorded and the collected timestamps were analyzed.</p>
<p>The results from this study are presented in detail and indicate that the use of passive haptics in this application has a statistically significant impact on the user experience and affects their enjoyment, learning progress, as well as the perceived level of realism of the virtual reality simulation.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Assessing the Role of Virtual Reality with Passive Haptics in Music Conductor Education: A Pilot Study</title>
		<link>https://research.dwi.ufl.edu/projects/angelos/page/assessing-the-role-of-virtual-reality-with-passive-haptics-in-music-conductor-education-a-pilot-study/</link>
		
		<dc:creator><![CDATA[angelos]]></dc:creator>
		<pubDate>Fri, 10 Jul 2020 15:01:47 +0000</pubDate>
				<guid isPermaLink="false">https://research.dwi.ufl.edu/people/angelos/?post_type=product&#038;p=71</guid>

					<description><![CDATA[This paper presents a novel virtual reality system that offers immersive experiences for instrumental music conductor training. The system utilizes passive haptics that bring physical objects of interest, namely the baton and the music stand, within a virtual concert hall environment. Real-time object and finger tracking allow the users to behave naturally on a virtual<span class="read-more-faq"><a href="https://research.dwi.ufl.edu/projects/angelos/page/assessing-the-role-of-virtual-reality-with-passive-haptics-in-music-conductor-education-a-pilot-study/">Read More</a></span>]]></description>
										<content:encoded><![CDATA[<p><iframe src="https://www.youtube.com/embed/0wY5gh8elq4?feature=oembed" width="1200" height="600" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>This paper presents a novel virtual reality system that offers immersive experiences for instrumental music conductor training. The system utilizes passive haptics that bring physical objects of interest, namely the baton and the music stand, within a virtual concert hall environment. Real-time object and finger tracking allow the users to behave naturally on a virtual stage without significant deviation from the typical performance routine of instrumental music conductors. The proposed system was tested in a pilot study (n=13) that assessed the role of passive haptics in virtual reality by comparing our proposed “smart baton” with a traditional virtual reality controller. Our findings indicate that the use of passive haptics increases the perceived level of realism and that their virtual appearance affects the perception of their physical characteristics.</p>
<p>The use of computer systems in instrumental music conductor education has been a well studied topic even outside the area of virtual reality [1]. Several systems have been proposed that offer targeted learning experiences [2,3] which may also combine gamified elements [6]. In the past decades, several visual interfaces have been designed using the available technologies at each given period of time [4,5,7], which most recently included eye tracking [8] and augmented and virtual reality platforms [3].</p>
<p>Recent advances in real-time object tracking and the availability of such systems as mainstream consumer products has opened new possibilities for virtual reality applications [13, 14,]. It has been shown that the use of passive haptics in VR contribute to a sensory-rich experience [15,16], as users have now the opportunity to hold and feel the main objects of interaction within a given immersive environment, such as tools, handles, and other instruments. For example, tracking the location of a real piano can help beginners learn how to play it using virtual reality [20]. However, the use of passive haptics in virtual environments for music education is an understudied area, because it requires precise real-time tracking of objects that are significantly smaller than a piano, such as hand held musical instruments, bows, batons, etc.</p>
<p>In this paper, we present a novel system for enhancing the training of novice instrumental music conductors through a tangible virtual environment. For the purposes of the proposed system a smart baton and a smart music stand have been designed using commercially available tracking sensors (VIVE trackers). The users wear a high-fidelity virtual reality headset (HTC VIVE), which renders the environment of a virtual concert hall from the conductor’s standpoint. Within this environment, the users can feel the key objects of interaction within their reach, namely the baton, the music stand, and the floor of the stage through passive haptics. A real-time hand and finger motion tracking system continuously tracks the left hand of the user in addition to the tracking of the baton, which is usually held in the right hand. This setup creates a natural user interface that allows the conductors to perform naturally on a virtual stage, thus creating a highly immersive training experience.</p>
<p>The main goals of the proposed system are the following: a) Enhance the traditional training of novice instrumental music conductors by increasing their practice time without requiring additional space allocation or time commitment from music players, which is also cost-effective. b) Provide an interface for natural user interaction that does not deviate from the traditional environment of conducting, including the environment, the tools, and the user behavior (hand gesture, head pose, and body posture), thus making the acquired skills highly transferable to the real-life scenario. c) Just-in-time feedback is essential in any educational setting, therefore one of the goals of the proposed system is to generate quantitative feedback on the timeliness of their body movement and the corresponding music signals. d) Last but not least, the proposed system recreates the conditions of a real stage performance, which may help the users reduce stage fright within a risk-free virtual environment [9,10,11,12].</p>
<p>A small scale pilot study (n=13) was performed in order to assess the proposed system and particularly the role of passive haptics in this virtual reality application. The main focus of the study was to test whether the use of passive haptics increases the perceived level of realism in comparison to a typical virtual reality controller, and whether the virtual appearance of a real physical object, such as the baton, affects the perception of its physical characteristics. These hypotheses were tested using A/B tests followed by short surveys. The statistical significance of the collected data was calculated, and the results are discussed in detail.  The reported findings support our hypotheses and set the basis for a larger-scale future study.</p>
<p><iframe src="https://www.youtube.com/embed/m8e_YHEgglo?feature=oembed" width="1200" height="600" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Discover DaVinci – A Gamified Blockchain Learning App</title>
		<link>https://research.dwi.ufl.edu/projects/angelos/page/discover-davinci-a-gamified-blockchain-learning-app/</link>
		
		<dc:creator><![CDATA[angelos]]></dc:creator>
		<pubDate>Sun, 03 May 2020 20:56:49 +0000</pubDate>
				<guid isPermaLink="false">https://research.dwi.ufl.edu/people/angelos/?post_type=product&#038;p=148</guid>

					<description><![CDATA[Discover DaVinci is a novel augmented reality system that incorporates blockchain technology with experiential learning to engage participants in an interactive discovery of Leonardo da Vinci’s ouvre. In the true spirit of this “Renaissance man”, Discover DaVinci explores new ideas and technologies “ahead of their time”. In order to illustrate the emerging potential at the<span class="read-more-faq"><a href="https://research.dwi.ufl.edu/projects/angelos/page/discover-davinci-a-gamified-blockchain-learning-app/">Read More</a></span>]]></description>
										<content:encoded><![CDATA[<p>Discover DaVinci is a novel augmented reality system that incorporates blockchain technology with experiential learning to engage participants in an interactive discovery of Leonardo da Vinci’s ouvre. In the true spirit of this “Renaissance man”, Discover DaVinci explores new ideas and technologies “ahead of their time”.</p>
<p>In order to illustrate the emerging potential at the intersection of art and blockchain, we present a case study of a new interactive system produced at the University of Florida Digital Worlds Institute.</p>
<p><iframe loading="lazy" src="https://www.youtube.com/embed/0uKWQFqtIuA?feature=oembed" width="800" height="600" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>The technologies of mobile computing, augmented reality (AR), and blockchain are starting to merge, creating new opportunities and scenarios to interact with our environment. In AR we can look at virtual objects superimposed within a real environment and resize them, rotate them, explore and interact with them on multiple levels. With the combination of AR and blockchain, we can create a system capable of keeping track of digital assets located virtually in 3D space (i.e., spatial computing). The global scale of blockchain and related technologies heightens the potential for trade and digital distribution with a fully automated and trusted way to keep track of their creations without a “middle-man”.</p>
<p>Discover DaVinci is a novel educational tool that teaches concepts of blockchain technology through an augmented reality experiential learning game.</p>
<p>This project was developed in collaboration with several units from the University of Florida and industry partners:<br />
• Digital Arts &amp; Sciences Faculty (Computer Science and Digital Worlds Institute)<br />
• Digital Worlds Studios’ Artists and Programmers<br />
• Gator Blockchain Club (gatorblockchainclub.com) – Student-run blockchain club at the University of Florida<br />
• Center for Innovation and Entrepreneurship (College of Business)<br />
• Creative Campus Committee at the University of Florida<br />
Industry Partners:<br />
• DLUX, decentralized content network (dlux.io)<br />
• Steem (steem.com), and Steemit (steemit.com)<br />
• A-Frame, web VR platform (aframe.io)</p>
<p>Discover DaVinci utilizes the format of a digital, collectible trading &amp; drafting card game with AR elements on the STEEM blockchain. Although each player “owns” their cards, all transactions are public. Every collectible card is a unique token, owned by the player – a digital asset registered to the player’s account. The aim is to draw new question cards daily, answer the questions about Leonardo DaVinci, collect the special AR invention cards, and ultimately submit the accumulated card collection into a drawing for prizes. The app was developed to honor the 500th anniversary of Leonardo Davinci by promoting new and innovative technologies.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Custom Virtual Reality System with Real-Time Therapist Interactions to Enhance Home Exercise Performance and Adherence</title>
		<link>https://research.dwi.ufl.edu/projects/angelos/page/custom-virtual-reality-system-with-real-time-therapist-interactions-to-enhance-home-exercise-performance-and-adherence/</link>
		
		<dc:creator><![CDATA[angelos]]></dc:creator>
		<pubDate>Wed, 12 Feb 2020 15:04:58 +0000</pubDate>
				<guid isPermaLink="false">https://research.dwi.ufl.edu/people/angelos/?post_type=product&#038;p=73</guid>

					<description><![CDATA[Purpose/Hypothesis: Following lower extremity (LE) joint replacement, patients are increasingly prescribed virtual reality-based home exercise programs (HEP). One goal of virtual reality (VR) use is to promote HEP adherence. Exercise adherence, as well as exercise performance, is increased with human interaction and real-time therapist feedback, which is not commonly incorporated in commercially available VR systems.<span class="read-more-faq"><a href="https://research.dwi.ufl.edu/projects/angelos/page/custom-virtual-reality-system-with-real-time-therapist-interactions-to-enhance-home-exercise-performance-and-adherence/">Read More</a></span>]]></description>
										<content:encoded><![CDATA[<p><strong>Purpose/Hypothesis:</strong><br />
Following lower extremity (LE) joint replacement, patients are increasingly prescribed virtual reality-based home exercise programs (HEP). One goal of virtual reality (VR) use is to promote HEP adherence. Exercise adherence, as well as exercise performance, is increased with human interaction and real-time therapist feedback, which is not commonly incorporated in commercially available VR systems. To address these limitations, a custom VR system was developed using an infrared camera for motion tracking, avatar streaming, and real-time remote therapist interactions. The primary aim of this study was to evaluate the use of this custom VR system on HEP performance in adults post LE joint replacement. We also examined patient and therapist opinions of VR system feedback features and ability to improve HEP adherence.</p>
<p><strong>Number of Subjects:</strong><br />
14 patients (11 female; 62.5±7.5 years) with unilateral hip (n=6) or knee (n=8) replacements (4.6±5.9 months post-surgery) and 11 therapists (6 PT, 4 OT, 1 COTA; female; &gt;2 yrs experience) participated.</p>
<p><strong>Materials/Methods:</strong><br />
Subjects completed two random-ordered LE exercise conditions using either the custom VR system or a conventional HEP with diagrams and written instructions while therapists observed remotely via video streaming. Four standing exercises were performed (hip flexion, abduction, extension, squats). Instructions and verbal feedback were standardized, and 3-D LE motions were recorded. Exercise performance was assessed by calculating peak joint angles and movement velocities. The effect of remote therapist interaction and verbal feedback on exercise performance during the VR condition was assessed by calculation of peak joint angles during aberrant, compensatory movements (i.e. trunk lean). Exercise performance during the two conditions was compared using paired t-tests. Patient and therapist preferences were assessed using standardized questionnaires with open-ended and Likert scale-based items.</p>
<p><strong>Results:</strong><br />
Peak joint angles during the two conditions were not different (p&gt;.05), but movements were slower with VR use for 3 of 4 exercises (p&lt;.05) and compensations were reduced with remote therapist interactions and verbal feedback. 100% of patient and therapist participants reported preferences for remote interactions including verbal feedback and interactions with streaming avatars to display real-time movements. 79% of patients and 91% of therapists reported agreement that the VR system could improve HEP adherence.</p>
<p><strong>Conclusion:</strong><br />
A custom VR system that incorporates real-time remote therapist interactions improved HEP performance in individuals post LE joint replacement. Both patients and therapists reported high preferences for real-time interactions.</p>
<p><strong>Clinical Relevance:</strong><br />
VR systems should consider the role of real-time therapist interactions to promote engagement and adherence to HEPs, as well as provide opportunity for feedback to enhance exercise performance. Further, web-based systems can allow for multi-user group exercise sessions and engagement for those in ru</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Development and validation of the automated imaging differentiation in parkinsonism (AID-P): a multicentre machine learning study</title>
		<link>https://research.dwi.ufl.edu/projects/angelos/page/development-and-validation-of-the-automated-imaging-differentiation-in-parkinsonism-aid-p-a-multicentre-machine-learning-study/</link>
		
		<dc:creator><![CDATA[angelos]]></dc:creator>
		<pubDate>Tue, 27 Aug 2019 18:51:10 +0000</pubDate>
				<guid isPermaLink="false">https://research.dwi.ufl.edu/people/angelos/?post_type=product&#038;p=127</guid>

					<description><![CDATA[Background Development of valid, non-invasive biomarkers for parkinsonian syndromes is crucially needed. We aimed to assess whether non-invasive diffusion-weighted MRI can distinguish between parkinsonian syndromes using an automated imaging approach. Methods We did an international study at 17 MRI centres in Austria, Germany, and the USA. We used diffusion-weighted MRI from 1002 patients and the<span class="read-more-faq"><a href="https://research.dwi.ufl.edu/projects/angelos/page/development-and-validation-of-the-automated-imaging-differentiation-in-parkinsonism-aid-p-a-multicentre-machine-learning-study/">Read More</a></span>]]></description>
										<content:encoded><![CDATA[<h3>Background</h3>
<div class="section-paragraph">Development of valid, non-invasive biomarkers for parkinsonian syndromes is crucially needed. We aimed to assess whether non-invasive diffusion-weighted MRI can distinguish between parkinsonian syndromes using an automated imaging approach.</div>
<h3>Methods</h3>
<div class="section-paragraph">We did an international study at 17 MRI centres in Austria, Germany, and the USA. We used diffusion-weighted MRI from 1002 patients and the Movement Disorders Society Unified Parkinson&#8217;s Disease Rating Scale part III (MDS-UPDRS III) to develop and validate disease-specific machine learning comparisons using 60 template regions and tracts of interest in Montreal Neurological Institute space between Parkinson&#8217;s disease and atypical parkinsonism (multiple system atrophy and progressive supranuclear palsy) and between multiple system atrophy and progressive supranuclear palsy. For each comparison, models were developed on a training and validation cohort and evaluated in an independent test cohort by quantifying the area under the curve (AUC) of receiving operating characteristic curves. The primary outcomes were free water and free-water-corrected fractional anisotropy across 60 different template regions.</div>
<h3>Findings</h3>
<div class="section-paragraph">In the test cohort for disease-specific comparisons, the diffusion-weighted MRI plus MDS-UPDRS III model (Parkinson&#8217;s disease <em>vs</em> atypical parkinsonism had an AUC 0·962; multiple system atrophy <em>vs</em> progressive supranuclear palsy AUC 0·897) and diffusion-weighted MRI only model had high AUCs (Parkinson&#8217;s disease <em>vs</em> atypical parkinsonism AUC 0·955; multiple system atrophy <em>vs</em> progressive supranuclear palsy AUC 0·926), whereas the MDS-UPDRS III only models had significantly lower AUCs (Parkinson&#8217;s disease <em>vs</em> atypical parkinsonism 0·775; multiple system atrophy <em>vs</em> progressive supranuclear palsy 0·582). These results indicate that a non-invasive imaging approach is capable of differentiating forms of parkinsonism comparable to current gold standard methods.</div>
<h3>Interpretations</h3>
<div class="section-paragraph">This study provides an objective, validated, and generalisable imaging approach to distinguish different forms of parkinsonian syndromes using multisite diffusion-weighted MRI cohorts. The diffusion-weighted MRI method does not involve radioactive tracers, is completely automated, and can be collected in less than 12 min across 3T scanners worldwide. The use of this test could positively affect the clinical care of patients with Parkinson&#8217;s disease and parkinsonism and reduce the number of misdiagnosed cases in clinical trials.</div>
<h3>Funding</h3>
<div class="section-paragraph">National Institutes of Health and Parkinson&#8217;s Foundation.</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Learning Programming Languages as Shortcuts to Natural Language Token Replacements</title>
		<link>https://research.dwi.ufl.edu/projects/angelos/page/learning-programming-languages-as-shortcuts-to-natural-language-token-replacements/</link>
		
		<dc:creator><![CDATA[angelos]]></dc:creator>
		<pubDate>Mon, 26 Nov 2018 12:33:36 +0000</pubDate>
				<guid isPermaLink="false">https://research.dwi.ufl.edu/people/angelos/?post_type=product&#038;p=131</guid>

					<description><![CDATA[The basic knowledge of computer programming is generally considered a valuable skill for educated citizens outside computer science and engineering professions. However, learning programming can be a challenging task for beginners of all ages especially outside of formal CS education. This paper presents a novel source code editing method that assists novice users understand the<span class="read-more-faq"><a href="https://research.dwi.ufl.edu/projects/angelos/page/learning-programming-languages-as-shortcuts-to-natural-language-token-replacements/">Read More</a></span>]]></description>
										<content:encoded><![CDATA[<p><iframe loading="lazy" src="https://www.youtube.com/embed/DOQcUWMz8xU?feature=oembed" width="1200" height="600" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>The basic knowledge of computer programming is generally considered a valuable skill for educated citizens outside computer science and engineering professions. However, learning programming can be a challenging task for beginners of all ages especially outside of formal CS education. This paper presents a novel source code editing method that assists novice users understand the logic and syntax of the computer code they type. The method is based on the concept of text replacements that interactively provide the learners with declarative knowledge and help them transform it to procedural knowledge, which has been shown to be more robust against decay. An active tokenization algorithm splits the typed code into tokens as they are typed and replaces them with a pre-aligned translation in a human natural language. The feasibility of the proposed method is demonstrated in seven structurally different natural languages (English, Chinese, German, Greek, Italian, Spanish, and Turkish) using examples of computer code in ECMAScript (JavaScript).</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Real-time reconstruction of the human body and automated avatar synthesis</title>
		<link>https://research.dwi.ufl.edu/projects/angelos/page/real-time-reconstruction-of-the-human-body-and-automated-avatar-synthesis/</link>
		
		<dc:creator><![CDATA[angelos]]></dc:creator>
		<pubDate>Tue, 06 Nov 2018 19:37:12 +0000</pubDate>
				<guid isPermaLink="false">https://research.dwi.ufl.edu/people/angelos/?post_type=product&#038;p=241</guid>

					<description><![CDATA[Systems and Techniques for real-time 3D reconstruction of the human body are described. Avatars (the rendered 3D reconstruction of the human body) can be generated from real-time captured RGB-D images of a person. Avatars can be synthesized from the RGB-D data received from a single RGB-D camera by performing body segmentation (into cylindrical-type objects) and<span class="read-more-faq"><a href="https://research.dwi.ufl.edu/projects/angelos/page/real-time-reconstruction-of-the-human-body-and-automated-avatar-synthesis/">Read More</a></span>]]></description>
										<content:encoded><![CDATA[<p>Systems and Techniques for real-time 3D reconstruction of the human body are described. Avatars (the rendered 3D reconstruction of the human body) can be generated from real-time captured RGB-D images of a person. Avatars can be synthesized from the RGB-D data received from a single RGB-D camera by performing body segmentation (into cylindrical-type objects) and dynamic robust data filtering on sequential frames of the captured data. Cylindrical-type objects of the body, including arms, legs, and torso are parameterized using tensor splines; and positive-definite constrains are imposed to the estimated tensor splines using a Riemannian metric defined on the space of positive-definite tensor splines. These generated avatars have an articulated body with separately translatable and rotatable arms, legs, and other limbs or cylindrical features.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Depth map of the Rosetta Stone</title>
		<link>https://research.dwi.ufl.edu/projects/angelos/page/depth-map-of-the-rosetta-stone/</link>
		
		<dc:creator><![CDATA[angelos]]></dc:creator>
		<pubDate>Thu, 28 Jun 2018 15:09:47 +0000</pubDate>
				<guid isPermaLink="false">https://research.dwi.ufl.edu/people/angelos/?post_type=product&#038;p=75</guid>

					<description><![CDATA[This artifact depicts the depth map of the Rosetta stone, which was algorithmically generated in 2018 as part of the Digital Rosetta Stone project. The Digital Rosetta Stone is a project developed at Leipzig University by the Chair of Digital Humanities and the Egyptological Institute/Egyptian Museum Georg Steindorff in collaboration with the British Museum and<span class="read-more-faq"><a href="https://research.dwi.ufl.edu/projects/angelos/page/depth-map-of-the-rosetta-stone/">Read More</a></span>]]></description>
										<content:encoded><![CDATA[<p>This artifact depicts the depth map of the Rosetta stone, which was algorithmically generated in 2018 as part of the Digital Rosetta Stone project. The Digital Rosetta Stone is a project developed at Leipzig University by the Chair of Digital Humanities and the Egyptological Institute/Egyptian Museum Georg Steindorff in collaboration with the British Museum and the Digital Epigraphy and Archaeology Project of the University of Florida. The aims of the project are to produce a collaborative digital edition of the Rosetta Stone, address standardization and customization issues for the scholarly community, create data that can be used by students to understand the document in terms of language and content, and produce a high-resolution 3D model of the inscription. The three versions of the text were transcribed and outputted in XML, according to the EpiDoc guidelines. Next, the versions were aligned with the Ugarit iAligner tool that supports the alignment of ancient texts with modern languages, such as English and German. All three texts were then parsed syntactically and morphologically through Treebank annotation. Finally, the project explored new 3D-digitization methodologies of the Rosetta Stone in the British Museum that enhances traditional archaeological methods and facilitates the study of the artifact. The results of this work were used in different courses in Digital Humanities, Digital Philology, and Egyptology.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Name Tags and Pipes: Assessing the Role of Metaphors in Students’ Early Exposure to Computer Programming Using Emoticoding</title>
		<link>https://research.dwi.ufl.edu/projects/angelos/page/name-tags-and-pipes-assessing-the-role-of-metaphors-in-students-early-exposure-to-computer-programming-using-emoticoding/</link>
		
		<dc:creator><![CDATA[angelos]]></dc:creator>
		<pubDate>Thu, 28 Jun 2018 12:48:23 +0000</pubDate>
				<guid isPermaLink="false">https://research.dwi.ufl.edu/people/angelos/?post_type=product&#038;p=132</guid>

					<description><![CDATA[This paper presents a case study for assessing the effect of emoticoding during the students’ first encounter with text-based coding interfaces, in which period a student could have a deeply disappointing experience that may lead to “blank page trauma” as well as negative attitude towards the subject. A prototype metaphor-based source code editor was developed<span class="read-more-faq"><a href="https://research.dwi.ufl.edu/projects/angelos/page/name-tags-and-pipes-assessing-the-role-of-metaphors-in-students-early-exposure-to-computer-programming-using-emoticoding/">Read More</a></span>]]></description>
										<content:encoded><![CDATA[<p><iframe loading="lazy" src="https://www.youtube.com/embed/Lsn6bj3X8o8?feature=oembed" width="1200" height="600" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>This paper presents a case study for assessing the effect of emoticoding during the students’ first encounter with text-based coding interfaces, in which period a student could have a deeply disappointing experience that may lead to “blank page trauma” as well as negative attitude towards the subject. A prototype metaphor-based source code editor was developed using novel human-computer interaction mechanics based on the concept of emoticon-like scripting. Similarly to the use of shortcuts for typing emoticons in social media, visual or textual replacements appear in the proposed text editor when the user types complete valid tokens from a given programming language. Appropriate metaphors can be used in the design of the token replacements so that they are appealing to a particular age, gender, or cultural groups of users. Quantitative analysis of data from 5<sup>th</sup>-grade students (n = 40) shows that metaphor-based emoticoding improves significantly the students’ performance in terms of syntax recall when they transition from block- to text-based programming in comparison to transitioning without emoticoding.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>A 3D Body Posture Analysis Framework During Merging And Lane Changing Maneuvers</title>
		<link>https://research.dwi.ufl.edu/projects/angelos/page/a-3d-body-posture-analysis-framework-during-merging-and-lane-changing-maneuvers/</link>
		
		<dc:creator><![CDATA[angelos]]></dc:creator>
		<pubDate>Sat, 12 May 2018 18:06:35 +0000</pubDate>
				<guid isPermaLink="false">https://research.dwi.ufl.edu/people/angelos/?post_type=product&#038;p=79</guid>

					<description><![CDATA[Although significant advances have been done with respect to vehicle technology and roadway construction, driver behavior remains the number one contributing factor of traffic crashes worldwide. Studies show that one of the major causes of crashes is driver inattention, which may occur when drivers are involved with secondary activities (e.g. texting, talking on the phone,<span class="read-more-faq"><a href="https://research.dwi.ufl.edu/projects/angelos/page/a-3d-body-posture-analysis-framework-during-merging-and-lane-changing-maneuvers/">Read More</a></span>]]></description>
										<content:encoded><![CDATA[<p>Although significant advances have been done with respect to vehicle technology and roadway construction, driver behavior remains the number one contributing factor of traffic crashes worldwide. Studies show that one of the major causes of crashes is driver inattention, which may occur when drivers are involved with secondary activities (e.g. texting, talking on the phone, or eating), and when they fail to follow the cues of the surrounding environment while driving. The objective of this study was to develop a method that monitors driver body posture and movements inside the cabin and test it among different drivers when performing merging and lane changing maneuvers, since these types of maneuvers require significant body movement and may also result in unsafe situations. The developed method was applied in a naturalistic setting where 35 drivers were invited to participate. Participants’ 3D body posture was recorded with the use of a low-cost infrared depth sensor (Microsoft Kinect). Participants’ eye gaze was also recorded with the help of an eye-tracking equipment. This paper presents analysis results of 3D body posture in conjunction with the eye tracking information during 236 merging and 287 lane changing maneuvers.</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
